{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ST5242_HW3_Yiqiao_Yin_YY2502.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "6qRmNrKYsqdS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# HOMEWORK\n",
        "\n",
        "This is Homework #3. My name is Yiqiao Yin and my UNI is yy2502. I approve this message. "
      ]
    },
    {
      "metadata": {
        "id": "4diWaPCzmgvz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PROBLEM 1 (Short Questions)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Eu3cYU6Q3OEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (a)\n",
        "\n",
        "Suppose you have an algorithm that, when $n$ times, generates $n$ independent samples from a density $p$. How do you generate $n$ independent points distributed uniformly on the area under the curve $p$?\n",
        "\n",
        "Given density $p$, we can draw $X_i$ from $p(x_i)$, e.g. $X_i \\sim p(x_i)$. Moreover, we also want to draw $Y_i$ from uniform distribution, e.g. $Y_i \\sim \\text{Unif}(0, p(x_i))$. Thus, we have pair of points $(X_i, Y_i)$ independent and unfiromly under the area of curve $p$. "
      ]
    },
    {
      "metadata": {
        "id": "WhfMbVfJ7GJt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (b)\n",
        "\n",
        "A logistic regression classifier $\\sigma(v^t x - c)$ is trained by fitting the vector $v$ and offset $c$ using an optimization algorithm. How does overfitting occur?\n",
        "\n",
        "Logistic regression classifier is trained given data $x$. One can always increase the size of $x$ and fit a high dimensional model to a data without any specific purpose. What would happen is that the fitted model will tend to the indicating function. Training error will eventually decrease while validating error will decrease first and increase as dimension increases and can potentially lead to bad generalization. This phenomenon is overfitting."
      ]
    },
    {
      "metadata": {
        "id": "De_qdBmZ7qSr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (c) \n",
        "\n",
        "Suppose the variables $Z_1, ..., Z_n$ in the graphical model below are unobserved. Are $X_n$ and $X_2$ dependent or independent? \n",
        "\n",
        "They are dependent because the directed graphical model works like a flow chain passing information from one node to another as long as they are connected with a directed arrow. In this case, provided any node between $Z_2$ and $Z_n$ will form a flow chart and both $X_2$ and $X_n$ will be dependent on $Z_2$. Hence, they are dependent. "
      ]
    },
    {
      "metadata": {
        "id": "gV9grTIj8f99",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PROBLEM 2 XOR NETWORK\n",
        "\n",
        "Consider a neural network which\n",
        "\n",
        "- Takes inputs in $x = (x_1, x_2) \\in \\{-1, 1\\}^2$\n",
        "- Has a single hidden layer with two vertices\n",
        "- Represents the function\n",
        "$ f(x) := \\left\\{\n",
        "\\begin{array}{lcl}\n",
        "1 && \\text{ if } x_1 = x_2 \\\\\n",
        "0 && \\text{otherwise} \\\\\n",
        "\\end{array}\n",
        "\\right.$\n",
        "\n",
        "There several possible networks with these properties. Let us define the following such that the above premises are satisfied. \n",
        "\n",
        "- Define the variables: $X = (x_1, x_2) \\in \\{-1, 1\\}^2$;\n",
        "- Define the weights to the first hidden layer: $(w_{11}^1, w_{12}^1, w_{21}^1, w_{22}^1, w_{31}^1 = w_{32}^2) = (1,-1,-1,1,-1)$;\n",
        "- Define $\\phi(\\cdot)_1^1 = \\phi(\\cdot)_2^1 = \\sigma(\\cdot)$; \n",
        "- Define weigts to the output function from the first hidden layer: $(w_{11}^2, w_{21}^2) = (1, -1)$;\n",
        "- Define output function to be indicating function, e.g. $\\mathbb{1}\\{X > 0\\}$. "
      ]
    },
    {
      "metadata": {
        "id": "wFrfm-Rv_Is2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PROBLEM 3 DIRICHLET DISTRIBUTION\n",
        "\n",
        "Consider a multinomial distribution on the set of categories $X = \\{1, 2, 3\\}$. Recall that the parameter space of this distribution (the set of all vectors $\\theta = (\\theta_1, \\theta_2, \\theta_3)$ with non-negative entries and $\\theta_1 + \\theta_2 + \\theta_3 = 1$) can be plotted as the area within a triangle, with each corner corresponding to one category. \n",
        "\n",
        "As shown as graph in homework, does the observed sample in this case consis of one data point in category 3, or of one observation each in category 1 and 2?\n",
        "\n",
        "In this case, we observe posterior distribution has tilted towards the direction of category 3. This is because we have observed data that fall in/next category 3. "
      ]
    },
    {
      "metadata": {
        "id": "G_9-d7jp_uZG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PROBLEM 4 NEURAL NETWORK\n",
        "\n",
        "Consider classifier on $\\mathbb{R}^2$, given neuralnetwork with $\\phi := \\mathbb{I}\\{x \\ge 0\\}$. Also suppose \n",
        "$$w := \n",
        "\\begin{pmatrix}\n",
        "1/\\sqrt{2} \\\\\n",
        "1/\\sqrt{2} \\\\\n",
        "\\end{pmatrix}\n",
        ",\n",
        "c:= \\frac{1}{2\\sqrt{2}}, \n",
        "x := \n",
        "\\begin{pmatrix}\n",
        "-3 \\\\\n",
        "0 \\\\\n",
        "\\end{pmatrix}\n",
        ",\n",
        "x' := \n",
        "\\begin{pmatrix}\n",
        "1/2 \\\\\n",
        "1/2 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "Compute the classification result for x and $x'$.\n",
        "\n",
        "We solve the following.\n",
        "\n",
        "For $x$ we compute activation input, writing it as $a$, as the following\n",
        "$$\n",
        "a' = \n",
        "\\begin{pmatrix}\n",
        "-3 \\\\\n",
        "0 \\\\\n",
        "\\frac{1}{2\\sqrt{2}} \\\\\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} & -1 \\\\\n",
        "\\end{pmatrix}\n",
        "= -\\frac{7}{2\\sqrt{2}} < 0\n",
        "$$\n",
        "and thus $\\phi(a) = 0$ since $a < 0$. The result for $x$ would be 0. \n",
        "\n",
        "We can proceed again the same procedure as above but with $x'$. Compute\n",
        "$$\n",
        "a' = \n",
        "\\begin{pmatrix}\n",
        "\\frac{1}{2} \\\\\n",
        "\\frac{1}{2} \\\\\n",
        "\\frac{1}{2\\sqrt{2}} \\\\\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} & -1 \\\\\n",
        "\\end{pmatrix}\n",
        "= \\frac{1}{2\\sqrt{2}}\n",
        "$$\n",
        "and thus $\\phi(a') = 1$ since $a' \\ge 0$. Thus, $x'$ is classified as 1."
      ]
    },
    {
      "metadata": {
        "id": "GnSsRlPwL6oi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PROBLEM 5 REJECTION AND IMPORTANCE SAMPLING\n",
        "\n",
        "Suppose that we need samples from a density on [0,1], given by\n",
        "$$p(x) = 2x$$\n",
        "We want to estimate the mean of $p$ using rejection sampling, and use the uniform distribution $q$ on [0,1] as proposal distribution. We scale $p$ to\n",
        "$$\\tilde{p} = \\frac{1}{M} p$$\n",
        "so that its density does not exceed $q$."
      ]
    },
    {
      "metadata": {
        "id": "uyDklVtAMgVw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (a) Optimal M\n",
        "\n",
        "What is the optimal choice for $M$ if we wish to keep the number of rejected samples as small as possible?\n",
        "\n",
        "We know $p(x) = 2x$ is a straight line that goes through $q \\sim \\text{Unif}(0,1)$. If we draw sufficient number of samples from $p(x)$, then we would expect half of the samples got rejected. In this case, we can scale $p(x)$ by using $M = 1/2$ so that $\\tilde{p}(x) = \\frac{1}{2} p(x) = \\frac{1}{2} (2x) = x$. "
      ]
    },
    {
      "metadata": {
        "id": "qAU7A46jrPvo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (b) Times to Draw Samples\n",
        "\n",
        "Compute the acceptance probability for the rejection sampling procedure (for the optimal choice of $M$). If we wish to obtain $m$ samples from the rejection sampling procedure, how many times $n$ do we have to sample from the proposal distribution on average?\n",
        "\n",
        "Consider $q(x) = Q$ and we have\n",
        "$$\n",
        "\\begin{array}{lcl}\n",
        "\\mathbb{P}(U \\le \\frac{p(Q)}{Mq(x)})\n",
        "&=& \\mathbb{E}[\\mathbb{P}(U \\le \\frac{p(Q)}{Mq(Q)})|Q] \\\\\n",
        "&=& \\frac{1}{M} \\int p(q) dq \\\\\n",
        "&=& 1/2 \\\\\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "Suppose we want to obtain $m$ samples with the above acceptance probability and also suppose we need $n$ times to do so. This means $\\frac{1}{2} n = m$ and we solve for $n = 2m$ times needed in order to sample $m$ samples."
      ]
    },
    {
      "metadata": {
        "id": "ntIRqxNJv0Hm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (c) Variance of the mean of importance sampling\n",
        "\n",
        "Now suppose we use importance sampling rather than rejection sampling, again with uniform proposal distribution. What is the variance of the importance sampling estimate of the mean, for $n$ samples?\n",
        "\n",
        "Compute the following\n",
        "$$\n",
        "\\begin{array}{lcl}\n",
        "\\text{Var}(\\bar{x})\n",
        "&=& \\frac{1}{n} \\text{var}(x) \\\\\n",
        "&=& \\frac{1}{n} (\\frac{1}{n} \\sum_{i=1}^n f(x) \\frac{p(x)}{q(x)}) \\\\\n",
        "&=& \\frac{1}{n^2} \\sum (x - x)^2 2x \\\\\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "Alternatively, we have:\n",
        "\n",
        "From premise, we have target distribution $p$ and proposal distribution $q$. Consider $f$ to be the integrand of $p$. Then we have\n",
        "$$\n",
        "\\begin{array}{lcl}\n",
        "\\mathbb{E}_q\\big(\\frac{f(\\cdot) p(\\cdot)}{q(\\cdot)}\\big)\n",
        "&=& \\int_Q \\frac{f(x)p(x)}{q(x)} q(x) dx \\\\\n",
        "&=& \\int f(x) p(x) dx = \\mu \\\\\n",
        "\\end{array}\n",
        "$$\n",
        "and thus we have importance sampling estimate of $\\mu$, which is\n",
        "$$\\hat{\\mu}_q = \\frac{1}{n} \\sum_{i=1}^n \\frac{f(x) p(x)}{q(x)}, \\text{ where } X \\sim q$$\n",
        "\n",
        "To find the variance of $\\mu_q$, we want to find $\\text{Var}(\\mu_q) = \\text{Var}(\\frac{1}{n} \\sum f(x) \\frac{p(x)}{q(x)}) = \\text{Var}(\\frac{1}{n} \\sum 2x^2)$. Hence, it is sufficient to find $\\text{Var}(2x^2) = 4\\text{Var}(x^2)$. By definition,\n",
        "$$\n",
        "\\begin{array}{lcl}\n",
        "\\text{Var}(x^2)\n",
        "&=& \\mathbb{E}x^4 - (\\mathbb{E}x)^2 \\\\\n",
        "&=& \\int_0^1 x^4 dx - (\\text{Var}(x) + (\\mathbb{E}x)^2) \\\\\n",
        "&=& \\frac{1}{5} - (\\frac{1}{12} + \\frac{1}{4}) \\\\\n",
        "&=& \\frac{4}{45} \\\\\n",
        "\\end{array}\n",
        "$$\n",
        "and hence we have $4\\text{Var}(x) = \\frac{16}{45}$ so that we have our final answer\n",
        "$$\\text{Var}(\\mu_q) = \\frac{16}{45n}$$"
      ]
    },
    {
      "metadata": {
        "id": "lDf1kQ7LyLpV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PROBLEM 6 REJECTION SAMPLING\n",
        "\n",
        "Let $p(\\cdot)$ be a density function on $\\mathbb{R}$, and suppose we want to estimate\n",
        "$$\\theta := \\mathbb{E}_{X \\sim p} [h(X)] = \\int h(x)p(x) dx$$\n",
        "\n",
        "One way of doing so is to draw samples from $p$ using a rejection sampler given a proposal density $r(\\cdot)$. We assume that we know a $k$ such that $p(x) \\le kr(x)$ for all $x \\in \\mathbb{R}$. In this question we will assume that $k > 1$. \n",
        "\n",
        "Consider the following variant of rejection sampling, where we instead keep all of the samples and label whether we would have accepted or rejcted them in a standard rejection sampler. That is, for $i = 1, ..., N$.\n",
        "\n",
        "- Sample $X_i \\sim p(\\cdot)$ and $U_i \\sim \\text{Unif}[0,1]$ independently\n",
        "- If $U_i \\le \\frac{p(X_i)}{kr(X_i)}$, set a label $Z_i = A(\\text{Accept})$; otherwise set $Z_i = R(\\text{Reject})$.\n",
        "\n",
        "Suppose all the labels are not either all $A$ or all $R$ (so e.g. $ARA$ is allowed but $RRR$ is not). Note that $X_i|Z_i = A$ has density $p(\\cdot)$. This follows because\n",
        "$$\n",
        "\\begin{array}{lcl}\n",
        "\\mathbb{P}(X_i \\le x|A)\n",
        "&=& \\mathbb{P}(X_i \\le x|U_i \\le \\frac{p(X_i)}{kr(X_i)}) \\\\\n",
        "&=& \\frac{\\mathbb{P}(X_i \\le x, U_i \\le \\frac{p(X_i)}{kr(X_i)})}{\\mathbb{P}(U_i \\le \\frac{p(X_i)}{kr(X_i)})} \\\\\n",
        "&=& \\frac{\\int_{-\\infty}^x [\\int_0^{p(x_i)/kr(x_i)}dy] r(x_i) dx_i}{\\int_{-\\infty}^{\\infty} [\\int_0^{p(x_i)/kr(x_i)}dy] r(x_i) dx_i} \\\\\n",
        "&=& \\int_{-\\infty}^x p(x_i) dx_i \\\\\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "One problem with a standard rejection sampler is that we will sample $N$ draws from $q$ but will only keep a potentially small fraction of them. The purpose of the variant described above is to try and use all $N$ draws in order to estimate $\\theta$. "
      ]
    },
    {
      "metadata": {
        "id": "d-juAuyf0CRW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (a) Find Density\n",
        "\n",
        "Find density of $X_i|Z_i = R$. \n",
        "\n",
        "We want to find $\\mathbb{P}(X_i \\le x|R)$ and then we can compute density function $f(X_i|Z_i) = \\frac{d}{d x_i} \\mathbb{P}(X_i \\le x|R)$. Compute the following\n",
        "\n",
        "$$\\begin{array}{lcl}\n",
        "\\mathbb{}P(X_i \\le x|R)\n",
        "&=& \\mathbb{P}(X_i \\le x|U_i > \\frac{p(x_i)}{kr(x_i)}) \\\\\n",
        "&=& \\frac{\\mathbb{P}(X_i \\le x, U_i > \\frac{p(x_i)}{k r(x_i)})}{\\mathbb{P}(U_i \\ge \\frac{p(x_i)}{kr(x_i)})} \\\\\n",
        "&=& \\frac{\\int_{-\\infty}^x(\\int_{p(x_i)/kr(x_i)}^1 dy)r(x_i) dx_i}{\\int_{-\\infty}^{\\infty}(\\int_{p(x_i)/kr(x_i)}^1 dy)r(x_i) dx_i} \\\\\n",
        "&=& \\frac{\\int_{-\\infty}^x(r(x_i) - \\frac{1}{k} p(x_i))dx_i}{\\int_{-\\infty}^{\\infty}(r(x_i) - \\frac{1}{k} p(x_i))dx_i} \\\\\n",
        "&=& \\frac{\\int_{-\\infty}^x r(x_i) dx_i - \\frac{1}{k} \\int_{-\\infty}^x p(x_i) dx_i}{\\int_{-\\infty}^{\\infty} r(x_i) dx_i - \\frac{1}{k} \\int_{-\\infty}^{\\infty} p(x_i) dx_i} \\\\\n",
        "&=& \\frac{k}{k-1} \\int_{-\\infty}^x r(x_i) dx_i - \\frac{1}{k-1} \\int_{-\\infty}^x p(x_i) dx_i \\\\\n",
        "\\end{array}$$\n",
        "thus, we have $\\frac{d}{dx_i} \\mathbb{P}(X_i \\le x|R) = \\frac{k}{k-1} r(x_i) - \\frac{1}{k-1} p(x_i) = \\frac{1}{k-1} (kr(x_i) - p(x_i))$. Hence, the density of $X_i|R$ would be \n",
        "$$f(X_i|R) = \\frac{1}{k-1}(kr(x_i) - p(x_i))$$"
      ]
    },
    {
      "metadata": {
        "id": "gS2sZkGg0Hiz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## (b) How estimator can be sampling estimate \n",
        "\n",
        "Consider\n",
        "$$\\delta := \\frac{1}{N}(\\sum_{i:Z_i = A} h(X_i) + \\sum_{i:Z_i = R} h(X_i)\\frac{(k-1) p(X_i)}{kr(X_i) - p(X_i)})$$\n",
        "Explain how $\\delta$ can be interpreted as an importance sampling estimate of $\\theta$. \n",
        "\n",
        "Importance sampling: we want to define importance weight: $\\frac{1}{N} \\sum h(x_i) \\frac{p(x_i)}{r(x_i)}$ where $p(x_i)$ is target distribution and $r(x_i)$ is proposal distribution. Conditioning on $Z_i$ to be accept or reject, we have \n",
        "$$X_i \\sim r(X_i) \\Rightarrow X_i \\sim r(X_i)|A \\sim p(x_i)$$\n",
        "$$\\text{or alternatively } X_i \\sim r(X_i) \\Rightarrow X_i \\sim r(X_i)|R \\sim f(\\cdot)$$\n",
        "\n",
        "We can write \n",
        "$$\\begin{array}{lcl}\n",
        "\\frac{1}{N} \\sum h(x_i) \\frac{p(x_i)}{r(x_i)}\n",
        "&=& \\frac{1}{N}\\big(\\sum_{i: Z_i = A} h(x_i) \\frac{p(x_i)}{r(x_i)|A} + \\sum_{i: Z_i = R} h(x_i) \\frac{p(x_i)}{r(x_i)|R}\\big) \\\\\n",
        "&=& \\frac{1}{N}\\big(\\sum_{i: Z_i = A} h(x_i) + \\sum_{i: Z_i = R} h(x_i) \\frac{p(x_i)}{\\frac{1}{k-1}(kr(x_i) - p(x_i))}\\big) \\\\\n",
        "&=& \\frac{1}{N}\\big(\\sum_{i: Z_i = A} h(x_i) + \\sum_{i: Z_i = R} h(x_i) \\frac{(k-1)p(x_i)}{(kr(x_i) - p(x_i))}\\big) \\\\\n",
        "\\end{array}$$\n",
        "which is defined as $\\delta$ as indicated in the problem. This expression is what we want in importance sampling conditioning on $Z_i$. "
      ]
    }
  ]
}
